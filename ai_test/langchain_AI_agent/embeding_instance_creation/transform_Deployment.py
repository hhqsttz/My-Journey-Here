

from sentence_transformers import SentenceTransformer

# from embeding_instance_creation.Deployment_of_the_model import model_dir

# Load the model
model = SentenceTransformer("Qwen/Qwen3-Embedding-0.6B")
a=model.encode(
["æˆ‘çˆ±ä½ "]*60,
show_progress_bar = True
)
print(a)
print(f"æ¨¡å‹é»˜è®¤è¾“å‡ºç»´åº¦: {model.get_sentence_embedding_dimension()}")


# çœ‹èµ·æ¥ä½ åœ¨æŸ¥çœ‹ `SentenceTransformer.encode()` æ–¹æ³•çš„å‚æ•°å®šä¹‰ã€‚è¿™æ˜¯ä¸€ä¸ªéå¸¸å¼ºå¤§çš„æ–¹æ³•ï¼Œæä¾›äº†å¾ˆå¤šé€‰é¡¹æ¥æ§åˆ¶åµŒå…¥ç”Ÿæˆçš„è¿‡ç¨‹ã€‚è®©æˆ‘ä¸ºä½ è¯¦ç»†è§£é‡Šæ¯ä¸ªå‚æ•°çš„ä½œç”¨å’Œç”¨æ³•ï¼š
#
# # ğŸ¯ SentenceTransformer.encode() æ–¹æ³•å‚æ•°è¯¦è§£
#
# ## ğŸ“‹ å‚æ•°æ¦‚è¿°
#
# ```python
# def encode(
#     sentences: str | list[str] | ndarray,           # è¦ç¼–ç çš„æ–‡æœ¬
#     prompt_name: str | None = None,                 # é¢„å®šä¹‰æç¤ºæ¨¡æ¿åç§°
#     prompt: str | None = None,                      # è‡ªå®šä¹‰æç¤ºæ–‡æœ¬
#     batch_size: int = 32,                           # æ‰¹å¤„ç†å¤§å°
#     show_progress_bar: bool | None = None,          # æ˜¯å¦æ˜¾ç¤ºè¿›åº¦æ¡
#     output_value: Literal["sentence_embedding", "token_embeddings"] | None = "sentence_embedding",  # è¾“å‡ºç±»å‹
#     precision: Literal["float32", "int8", "uint8", "binary", "ubinary"] = "float32",  # ç²¾åº¦æ ¼å¼
#     convert_to_numpy: bool = True,                  # è½¬æ¢ä¸ºnumpyæ•°ç»„
#     convert_to_tensor: bool = False,                # è½¬æ¢ä¸ºPyTorchå¼ é‡
#     device: str | list[str | device] | None = None, # è¾“å‡ºè®¾å¤‡
#     normalize_embeddings: bool = False,             # æ˜¯å¦æ ‡å‡†åŒ–åµŒå…¥
#     truncate_dim: int | None = None,                # æˆªæ–­ç»´åº¦
#     pool: dict[Literal["input", "output", "processes"], Any] | None = None,  # å¤šè¿›ç¨‹æ± 
#     chunk_size: int | None = None,                  # åˆ†å—å¤§å°
#     **kwargs: Any                                   # å…¶ä»–å‚æ•°
# ) -> list[Tensor] | ndarray | Tensor | dict[str, Tensor] | list[dict[str, Tensor]]:
# ```
#
# ## ğŸª æ ¸å¿ƒå‚æ•°è¯¦è§£
#
# ### 1. `sentences` - è¾“å…¥æ–‡æœ¬
# ```python
# # å•å¥æ–‡æœ¬
# embeddings = model.encode("è¿™æ˜¯ä¸€ä¸ªå¥å­")
#
# # å¤šå¥æ–‡æœ¬åˆ—è¡¨
# embeddings = model.encode(["å¥å­1", "å¥å­2", "å¥å­3"])
#
# # numpyæ•°ç»„ï¼ˆåŒ…å«å­—ç¬¦ä¸²ï¼‰
# sentences_array = np.array(["æ–‡æœ¬1", "æ–‡æœ¬2"])
# embeddings = model.encode(sentences_array)
# ```
#
# ### 2. `batch_size` - æ‰¹å¤„ç†å¤§å°
# ```python
# # å°æ‰¹é‡ï¼ˆå†…å­˜è¾ƒå°‘æ—¶ï¼‰
# embeddings = model.encode(sentences, batch_size=16)
#
# # å¤§æ‰¹é‡ï¼ˆæ€§èƒ½ä¼˜åŒ–ï¼‰
# embeddings = model.encode(sentences, batch_size=64)
#
# # è‡ªåŠ¨è°ƒæ•´ï¼ˆæ ¹æ®ç¡¬ä»¶ï¼‰
# embeddings = model.encode(sentences, batch_size="auto")
# ```
#
# ### 3. `output_value` - è¾“å‡ºç±»å‹
# ```python
# # é»˜è®¤ï¼šå¥å­åµŒå…¥ï¼ˆæ¨èï¼‰
# sentence_embeddings = model.encode(sentences, output_value="sentence_embedding")
#
# # è·å–æ‰€æœ‰tokençš„åµŒå…¥ï¼ˆç”¨äºç‰¹å®šä»»åŠ¡ï¼‰
# token_embeddings = model.encode(sentences, output_value="token_embeddings")
# # è¿”å›æ ¼å¼ï¼š{"input_ids": [...], "token_embeddings": [...]}
# ```
#
# ### 4. è¾“å‡ºæ ¼å¼æ§åˆ¶
# ```python
# # é»˜è®¤è¿”å›numpyæ•°ç»„ï¼ˆæ¨èï¼‰
# embeddings = model.encode(sentences, convert_to_numpy=True)
#
# # è¿”å›PyTorchå¼ é‡
# tensor_embeddings = model.encode(sentences, convert_to_tensor=True)
#
# # æŒ‡å®šè¾“å‡ºè®¾å¤‡
# gpu_embeddings = model.encode(sentences, device="cuda")
# ```
#
# ### 5. åµŒå…¥åå¤„ç†
# ```python
# # æ ‡å‡†åŒ–åµŒå…¥å‘é‡ï¼ˆå•ä½é•¿åº¦ï¼‰
# normalized_embeddings = model.encode(sentences, normalize_embeddings=True)
#
# # æˆªæ–­åˆ°æŒ‡å®šç»´åº¦
# truncated_embeddings = model.encode(sentences, truncate_dim=256)
# ```
#
# ### 6. è¿›åº¦å’Œæ€§èƒ½æ§åˆ¶
# ```python
# # æ˜¾ç¤ºè¿›åº¦æ¡ï¼ˆå¤„ç†å¤§é‡æ–‡æœ¬æ—¶ï¼‰
# embeddings = model.encode(sentences, show_progress_bar=True)
#
# # ä½¿ç”¨å¤šè¿›ç¨‹åŠ é€Ÿ
# embeddings = model.encode(sentences, pool={"processes": 4})
#
# # åˆ†å—å¤„ç†è¶…å¤§æ–‡æœ¬
# embeddings = model.encode(sentences, chunk_size=1000)
# ```
#
# ## ğŸš€ å®ç”¨ç¤ºä¾‹ç»„åˆ
#
# ### ç¤ºä¾‹1ï¼šåŸºç¡€ç”¨æ³•
# ```python
# # æœ€ç®€å•çš„ç”¨æ³•
# sentences = ["ä»Šå¤©å¤©æ°”çœŸå¥½", "äººå·¥æ™ºèƒ½å¾ˆæœ‰è¶£", "æœºå™¨å­¦ä¹ æ­£åœ¨æ”¹å˜ä¸–ç•Œ"]
# embeddings = model.encode(sentences)
#
# print(f"åµŒå…¥å½¢çŠ¶: {embeddings.shape}")  # (3, 1024)
# ```
#
# ### ç¤ºä¾‹2ï¼šé«˜æ€§èƒ½å¤„ç†
# ```python
# # å¤„ç†å¤§é‡æ–‡æœ¬çš„ä¼˜åŒ–é…ç½®
# large_corpus = ["æ–‡æœ¬{}".format(i) for i in range(1000)]
#
# embeddings = model.encode(
#     large_corpus,
#     batch_size=64,              # åˆé€‚çš„æ‰¹å¤„ç†å¤§å°
#     show_progress_bar=True,     # æ˜¾ç¤ºè¿›åº¦
#     normalize_embeddings=True,  # æ ‡å‡†åŒ–ä¾¿äºç›¸ä¼¼åº¦è®¡ç®—
#     device="cuda" if torch.cuda.is_available() else "cpu"
# )
# ```
#
# ### ç¤ºä¾‹3ï¼šé«˜çº§åŠŸèƒ½
# ```python
# # è·å–tokençº§åµŒå…¥ç”¨äºç‰¹å®šåˆ†æ
# text = "è‡ªç„¶è¯­è¨€å¤„ç†å¾ˆæœ‰è¶£"
# result = model.encode(
#     text,
#     output_value="token_embeddings",  # è·å–tokenåµŒå…¥
#     convert_to_tensor=True           # è¿”å›å¼ é‡
# )
#
# print("Token IDs:", result["input_ids"])
# print("TokenåµŒå…¥å½¢çŠ¶:", result["token_embeddings"].shape)
# ```
#
# ### ç¤ºä¾‹4ï¼šå†…å­˜ä¼˜åŒ–
# ```python
# # å†…å­˜å—é™ç¯å¢ƒä¸‹çš„é…ç½®
# embeddings = model.encode(
#     sentences,
#     batch_size=8,                   # å°æ‰¹é‡å‡å°‘å†…å­˜ä½¿ç”¨
#     precision="int8",               # ä½¿ç”¨8ä½æ•´æ•°èŠ‚çœç©ºé—´
#     truncate_dim=512,               # æˆªæ–­åˆ°è¾ƒå°ç»´åº¦
#     convert_to_numpy=True           # ä½¿ç”¨numpyè€ŒéPyTorch
# )
# ```
#
# ## ğŸ“Š å‚æ•°é€‰æ‹©æŒ‡å—
#
# | åœºæ™¯ | æ¨èå‚æ•°é…ç½® |
# | :--- | :--- |
# | **å¸¸è§„ä½¿ç”¨** | `batch_size=32, convert_to_numpy=True` |
# | **ç›¸ä¼¼åº¦è®¡ç®—** | `normalize_embeddings=True` |
# | **å¤§è§„æ¨¡å¤„ç†** | `batch_size=64, show_progress_bar=True, pool={"processes": 4}` |
# | **å†…å­˜ä¼˜åŒ–** | `batch_size=16, precision="int8", truncate_dim=256` |
# | **GPUåŠ é€Ÿ** | `device="cuda", convert_to_tensor=True` |
# | **è¯¦ç»†åˆ†æ** | `output_value="token_embeddings"` |
#
# ## âš ï¸ æ³¨æ„äº‹é¡¹
#
# 1.  **å†…å­˜ç®¡ç†**ï¼šå¤§æ‰¹é‡å¤„ç†ä¼šå ç”¨æ›´å¤šå†…å­˜ï¼Œè¯·æ ¹æ®ç¡¬ä»¶è°ƒæ•´ `batch_size`
# 2.  **ç²¾åº¦æƒè¡¡**ï¼šé™ä½ç²¾åº¦ï¼ˆå¦‚ `int8`ï¼‰å¯ä»¥èŠ‚çœç©ºé—´ä½†å¯èƒ½æŸå¤±ä¸€äº›ç²¾åº¦
# 3.  **æ ‡å‡†åŒ–æ—¶æœº**ï¼šå¦‚æœåç»­è¦è¿›è¡Œä½™å¼¦ç›¸ä¼¼åº¦è®¡ç®—ï¼Œå»ºè®®è®¾ç½® `normalize_embeddings=True`
# 4.  **è®¾å¤‡ä¸€è‡´æ€§**ï¼šç¡®ä¿è¾“å…¥è®¾å¤‡å’Œæ¨¡å‹è®¾å¤‡ä¸€è‡´ï¼Œé¿å…ä¸å¿…è¦çš„æ•°æ®ä¼ è¾“
#
# è¿™äº›å‚æ•°è®©ä½ èƒ½å¤Ÿç²¾ç»†æ§åˆ¶åµŒå…¥ç”Ÿæˆè¿‡ç¨‹ï¼Œé€‚åº”ä¸åŒçš„åº”ç”¨åœºæ™¯å’Œç¡¬ä»¶ç¯å¢ƒã€‚æ ¹æ®ä½ çš„å…·ä½“éœ€æ±‚é€‰æ‹©åˆé€‚çš„å‚æ•°ç»„åˆï¼