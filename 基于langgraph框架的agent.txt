对于agent来说其实就是对于两个方向做文章，提示词扩展，llm增强。

一.提示词

--这部分相当于 输入的设计，确保模型“收到的信息完整、明确、正确”。

llm自身具有推理预测能力，但是会出现幻觉，为了让其更精确的推理，给出提示词来调整方向。
首先是基础的提示词，给ai指定角色，说明其任务，可能是一个runnable对象，可能是一个callable对象，还可能是提示词模版。用户提出问题可能信息不全面，这时候会用到短期存储checkpoint和长期存储store来获取用户历史消息，喂给大模型来补充问题，如果遇到专业性问题，可以将相关知识资料通过embedding模型词嵌入到向量数据库，将补充过后的问题与向量数据库进行检索，检索出相关的context，与用户的问题一并交给llm来进行分析。

如果用户的问题更为复杂，需要实时的精确信息，这时候需要通过工具来获取。现在有四种常用方式：
1.自己写一个函数
2.继承BaseTool的工具类
3.runnable工具对象
4.基于mcp协议调用外部工具与数据源

二.llm

--负责真正的推理和生成。

改进的点主要是：
模型能力（推理、多模态）
稳定性（减少幻觉）
适配性（微调、LoRA、DPO 等）
效率（量化、加速推理、轻量部署）

三.后续发展推测

大模型应用的核心趋势了：模型本身已经很强大，行业现在主要是在探索各种应用场景，把大模型“接”到现实系统里，让它动起来、做事情。

 典型应用场景（现在行业都在尝试的方向）

1. UI 控制 / 自动化助手

例子：让大模型理解用户的自然语言指令，然后操作网页/桌面软件。

技术点：

工具调用（Function Calling）

UI 自动化（Selenium、Playwright、PyAutoGUI）

工作流编排（LangGraph，把 LLM→UI 操作串起来）

2. 知识问答 / 智能客服

企业内部文档、FAQ、售后服务机器人。

技术点：RAG + 长期记忆。

3. 数据分析 / 报表生成

用户用自然语言问：“帮我做个近三个月销售分析图”，AI 自动生成 SQL 查询 & 可视化图表。

技术点：SQL 生成 + Pandas/Numpy 调用 + 可视化工具。

4. 多模态应用

图片识别 + 文字分析（如：看图说话、PPT 生成）。

视频理解 + 视频生成（像 Sora）。

语音助手（语音输入 + 大模型理解 + 语音输出）。

5. 多智能体协作（MAS）

多个 Agent 各司其职，比如一个 Agent 负责搜索，一个 Agent 负责写代码，一个 Agent 负责测试。类似 AutoGen、CrewAI 的思路。

现在大模型的价值在于：
通过提示词+工具调用，把 LLM 的语言能力转化为现实系统的操作能力。

比如“控制 UI 界面”就是个典型案例：
用户一句话 → LLM 解析成操作 → 工具执行（点击、输入、切换） → 实际界面变化。
这类应用在 自动化办公、测试、智能助手 里特别有潜力。